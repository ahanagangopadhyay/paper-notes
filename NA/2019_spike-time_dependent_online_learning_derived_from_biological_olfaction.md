You can find the paper [here](https://www.frontiersin.org/articles/10.3389/fnins.2019.00656/full).

![#1589F0](https://placehold.it/15/1589F0/000000?text=+) **Summary**  

The authors propose a fully feedforward spiking neural network which uses principles from mammalian olfactory systems for signal restoration and classification. The learning rule is spike-time based, exhibits high classification accuracy after few-shot learning, and includes a none-of-the-above outcome to reflect classifier confidence. They demonstrate the performance of the algorithm on a machine olfaction dataset, where the challenges include relatively small training sets, variable stimulus concentrations and considerable sensor drift.

![#1589F0](https://placehold.it/15/1589F0/000000?text=+) **Proposed approach**  

Mostly, research in machine olfaction is devoted to sensor development, using technologies like MOS, high-density polymer sensors, surface acoustic wave sensors, etc. In contrast, the authors dedicated their efforts to the post-sensory networks of the biological olfactory system, and tried to extract and implement the computational principles that yield its unmatched performance.  

The network comprises a pre-processing layer of external tufted cells (ET) and periglomerular cells (PG) that takes in a high-dimensional vector of sensory inputs, and which is similar to the glomerular layer in the olfactory bulb (OB) of mammals. Outputs from this layer are processed by the External Plexiform Layer (EPL), that comprises mitral cells (MCs) activated by sensory inputs and inhibitory interneurons called granule cells (GCs). As a whole, the network is defined with a number of columns such that each column received input from one type of sensor. Each column comprises 1 ET and 1 PG cell for glomerular-layer preprocessing; as well as 1 MC and several GCs for odorant learning and classification.  

As in biological systems, sensory input is preprocessed by the glomerular layer for concentration tolerance, and the preprocessed input is transmitted to MCs. The MCs synaptically excite a number of random GCs across the entire network, whereas activated GCs synaptically inhibit MCs in their home column. For this paper, the inhibitory feedback weights were taken to be zero. The excitatory synapses followed a STDP-based learning rule for adapting their weights. Instead of taking the spike-times of the MCs as the model output, the binary vector describing the GC ensemble activity (spiking vs non-spiking) is taken to be the processed data for classification. 

The following data processing were done on the sensor data:  
- Sensor scaling: To compensate for heterogeneity in the scales of different sensors. For this, responses for each sensor were divided by the maximum response value of that sensor.  
- Unsupervised concentration tolerance: Effects of odor concentration changes on receptor activation patterns are often similar to the effects of changes in odor quality. In spite of this, MC spike rates are not strongly or uniformly affected by concentration changes, mostly because of a global inhibitory feedback mechanism in the deep glomerular layer. The authors implemented this tolerance mechanism as the graded inhibition of ET cells by PG interneurons in the glomerular layer. This ensures that the network can recognize odors at concentrations on which they have not been trained, whereas an estimate of the concentration can be made based on the amount of feedback. Here, sensor inputs were delivered directly to both ET and PG cells, following which PG cells inhibited all ET cells across all columns, leading to a normalization effect. The ET cells in turn excited the MC cells in their home columns.  

MCs and GCs are modeled as leaky integrate-and-fire neurons. For MCs, the input current corresponds to sensory inputs from ET cells, whereas for GC cells, it is the total synaptic input from pre-synaptic MCs. A gamma oscillation cycle was used to set up a spike precedence coding scheme for MCs, where earlier MC spike phases correspond to stronger sensor input and vice versa (so these weights were not learned). Excitatory MC-GC synapses were initialized with an uniformly distributed random probability of connection and the weights were modified according to STDP. When a presynaptic MC spiked before the postsynaptic GC within the same gamma cycle, the synapse weight was increased; whereas when an MC spiked after GC or a GC spiked without an MC spike, w was decremented. Synaptic weights were limited by an upper bound. This pairing of STDP + MC spike precedence coding produced a k-winners take all, transforming GCs into specialized cells that were only activated by a specific subset of size k across the ensemble of MCs. A high learning rate ensured that after a single learning cycle, each synapse could have one of only 3 values: w0 (initial weight), wmax (upper bound) or 0. The value of wmax was tuned based on validation set performance. Interestingly, the best validation set performance occured when wmax=w0, which means learning was only limited to long-term synaptic depression.  

For classification, the hamming distance between the binary vectors of GC activities during test was computed with the training set vectors, and the test odorant was classified based on the closest training sample. A test sample was treated as none-of-the-above if the hamming distance between the binary vectors was >0.5 for all classes.  

![#1589F0](https://placehold.it/15/1589F0/000000?text=+) **Results**  

The authors tested their proposed approach on the UCSD gas sensor drift dataset, which contains 13910 measurements from 16 chemosensors which were exposed to 6 odorants of various concentrations over a period of 3 years. So this dataset exhibits many of the challenges present in machine olfaction: sensor drift, varying odorant concentrations, etc. A randomly selected subset of concentrations for each odorant were used in training, while the remaining concentrations were used for validation and testing. The original dataset had 8 features/chemosensor, yielding a 128-dimensional feature vector for each odorant and concentration. However for this paper, the authors simply used 1 feature/chemosensor (the steady-state response level), which yielded an 8-dimensional feature vector for each data point.  
The proposed network, unlike ANNs, resists catastrophic forgetting and shows online learning. For example, after training the network on two odorants, it can already classify a test sample as odorant 1, odorant 2 or none of the above, with no need to train on the entire list of possible odorants. 
