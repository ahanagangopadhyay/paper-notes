You can find the paper [here](https://www.frontiersin.org/articles/10.3389/fnins.2019.00656/full).

![#1589F0](https://placehold.it/15/1589F0/000000?text=+) **Summary**  

The authors propose a fully feedforward spiking neural network which uses principles from mammalian olfactory systems for signal restoration and classification. The learning rule is spike-time based, exhibits high classification accuracy after few-shot learning, and includes a none-of-the-above outcome to reflect classifier confidence. They demonstrate the performance of the algorithm on a machine olfaction dataset, where the challenges include relatively small training sets, variable stimulus concentrations and considerable sensor drift.

![#1589F0](https://placehold.it/15/1589F0/000000?text=+) **Proposed approach**  

Mostly, research in machine olfaction is devoted to sensor development, using technologies like MOS, high-density polymer sensors, surface acoustic wave sensors, etc. In contrast, the authors dedicated their efforts to the post-sensory networks of the biological olfactory system, and tried to extract and implement the computational principles that yield its unmatched performance.  

The network comprises a pre-processing layer of external tufted cells (ET) and periglomerular cells (PG) that takes in a high-dimensional vector of sensory inputs, and which is similar to the glomerular layer in the olfactory bulb (OB) of mammals. Outputs from this layer are processed by the External Plexiform Layer (EPL), that comprises mitral cells (MCs) activated by sensory inputs and inhibitory interneurons called granule cells (GCs). As a whole, the network is defined with a number of columns such that each column received input from one type of sensor. Each column comprises 1 ET and 1 PG cell for glomerular-layer preprocessing; as well as 1 MC and several GCs for odorant learning and classification.  

As in biological systems, sensory input is preprocessed by the glomerular layer for concentration tolerance, and the preprocessed input is transmitted to MCs. The MCs synaptically excite a number of random GCs across the entire network, whereas activated GCs synaptically inhibit MCs in their home column. For this paper, the inhibitory feedback weights were taken to be zero. The excitatory synapses followed a STDP-based learning rule for adapting their weights. Instead of taking the spike-times of the MCs as the model output, the binary vector describing the GC ensemble activity (spiking vs non-spiking) is taken to be the processed data for classification. 

The following data processing were done on the sensor data:  
- Sensor scaling: To compensate for heterogeneity in the scales of different sensors. For this, responses for each sensor were divided by the maximum response value of that sensor.  
- Unsupervised concentration tolerance: Effects of odor concentration changes on receptor activation patterns are often similar to the effects of changes in odor quality. In spite of this, MC spike rates are not strongly or uniformly affected by concentration changes, mostly because of a global inhibitory feedback mechanism in the deep glomerular layer. The authors implemented this tolerance mechanism as the graded inhibition of ET cells by PG interneurons in the glomerular layer. This ensures that the network can recognize odors at concentrations on which they have not been trained, whereas an estimate of the concentration can be made based on the amount of feedback. Here, sensor inputs were delivered directly to both ET and PG cells, following which PG cells inhibited all ET cells across all columns, leading to a normalization effect. The ET cells in turn excited the MC cells in their home columns.  

MCs and GCs are modeled as leaky integrate-and-fire neurons. For MCs, the input current corresponds to sensory inputs from ET cells, whereas for GC cells, it is the total synaptic input from pre-synaptic MCs. A gamma oscillation cycle was used to set up a spike precedence coding scheme for MCs, where earlier MC spike phases correspond to stronger sensor input and vice versa.
