You can find the paper [here](https://www.frontiersin.org/articles/10.3389/fnins.2019.00656/full).

![#1589F0](https://placehold.it/15/1589F0/000000?text=+) **Summary**  

The authors propose a fully feedforward spiking neural network which uses principles from mammalian olfactory systems for signal restoration and classification. The learning rule is spike-time based, exhibits high classification accuracy after few-shot learning, and includes a none-of-the-above outcome to reflect classifier confidence. They demonstrate the performance of the algorithm on a machine olfaction dataset, where the challenges include relatively small training sets, variable stimulus concentrations and considerable sensor drift.

![#1589F0](https://placehold.it/15/1589F0/000000?text=+) **Proposed approach**  

Mostly, research in machine olfaction is devoted to sensor development, using technologies like MOS, high-density polymer sensors, surface acoustic wave sensors, etc. In contrast, the authors dedicated their efforts to the post-sensory networks of the biological olfactory system, and tried to extract and implement the computational principles that yield its unmatched performance.   
The network comprises a pre-processing layer of external tufted cells (ET) and periglomerular cells (PG) that takes in a high-dimensional vector of sensory inputs, and which is similar to the glomerular layer in the olfactory bulb (OB) of mammals. Outputs from this layer are processed by the External Plexiform Layer (EPL), that comprises mitral cells (MCs) activated by sensory inputs and inhibitory interneurons called granule cells (GCs). As a whole, the network is defined with a number of columns such that each column received input from one type of sensor. Each column comprises 1 ET and 1 PG cell for glomerular-layer preprocessing; as well as 1 MC and several GCs for odorant learning and classification.  
As in biological systems, sensory input is preprocessed by the glomerular layer for concentration tolerance, and the preprocessed input is transmitted to MCs. The MCs synaptically excite a number of random GCs across the entire network, whereas activated GCs synaptically inhibit MCs in their home column. For this paper, the inhibitory feedback weights were taken to be zero. The excitatory synapses followed a STDP-based learning rule for adapting their weights. Instead of taking the spike-times of the MCs as the model output, the binary vector describing the GC ensemble activity (spiking vs non-spiking) is taken to be the processed data for classification. 
